{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a90b0e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
    "from transformers.models.auto.tokenization_auto import AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b110a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "testin = [\"hello world!\",\"second input:\",\"third input:\"]\n",
    "testout = [\"hi!!!!!!!!\",\"yes youre second wow so great\",\"now finished\"]\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/nova/cs336/assignment5-alignment/models/Qwen2.5-Math-1.5B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a49c194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_tensor(io_len:list[tuple[int,int]])->torch.Tensor:\n",
    "    \"\"\"\n",
    "    根据已知的io长度制造mask，只显露出模型输出的部分，mask掉输入和尾部padding\n",
    "    \"\"\"\n",
    "    max_len = max([i + o for (i,o) in io_len])\n",
    "    res = []\n",
    "    for ilen, olen in io_len:\n",
    "        #print(\"i,o:\",ilen,olen)\n",
    "        imask = [0] * ilen\n",
    "        omask = [1] * olen\n",
    "        padmask = [0] * (max_len - ilen - olen)\n",
    "        res.append(imask + omask + padmask)\n",
    "    rest = torch.tensor(res)\n",
    "    return rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85186ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 14990,   1879,      0,   6023,  50667, 151643, 151643, 151643],\n",
       "         [  5569,   1946,     25,   9693,  70075,   2086,  35665,    773],\n",
       "         [ 31727,   1946,     25,   3328,   8060, 151643, 151643, 151643]]),\n",
       " 'labels': tensor([[  1879,      0,   6023,  50667, 151643, 151643, 151643, 151643],\n",
       "         [  1946,     25,   9693,  70075,   2086,  35665,    773,   2244],\n",
       "         [  1946,     25,   3328,   8060, 151643, 151643, 151643, 151643]]),\n",
       " 'response_mask': tensor([[0, 0, 1, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_prompt_and_output(\n",
    "        prompt_strs:list[str],\n",
    "        output_strs:list[str], \n",
    "        tokenizer:PreTrainedTokenizerBase ):\n",
    "    \"\"\"\n",
    "    Tokenize the prompt and output strings, and construct a mask that is 1 for the response tokens and 0 for other tokens (prompt or padding).\n",
    "    Args:\n",
    "        prompt_strs(list[str]): List of prompt strings.\n",
    "        output_strs(list[str]): List of output strings.\n",
    "        tokenizer(PreTrainedTokenizer): Tokenizer to use for tokenization.\n",
    "    Returns:\n",
    "        output(dict[str, torch.Tensor]): Let prompt_and_output_lens be a list containing the lengths of the tokenized prompt and output strings. Then the returned dictionary should have the following keys.\n",
    "        - input_ids: torch.Tensor of shape (batch_size, max(prompt_and_output_lens) - 1): the tokenized prompt and output strings, with the final token sliced off.\n",
    "        - labels: torch.Tensor of shape (batch_size, max(prompt_and_output_lens) - 1): shifted input ids, i.e., the input ids without the first token.\n",
    "        - response_mask: torch.Tensor of shape (batch_size, max(prompt_and_output_lens) - 1): a mask on the response tokens in the labels.\n",
    "    \"\"\"\n",
    "    # print(\"输入:\",prompt_strs)\n",
    "    # print(\"输出:\",output_strs)\n",
    "\n",
    "    assert len(prompt_strs) == len(output_strs) , \"输入与输出数量不等！\"\n",
    "    \n",
    "    prompt_ids = [tokenizer.encode(s) for s in prompt_strs]\n",
    "    #print(prompt_ids)\n",
    "\n",
    "    response_ids = [tokenizer.encode(s) for s in output_strs]\n",
    "    #print(response_ids)\n",
    "    \n",
    "    batch_ids = [p + r for p,r in zip(prompt_ids, response_ids)]\n",
    "    #print(batch_ids)\n",
    "\n",
    "    io_len = [(len(lp),len(lr)) for lp, lr in zip(prompt_ids, response_ids)]\n",
    "    #print(io_len)\n",
    "\n",
    "    max_len = max([len(io) for io in batch_ids])\n",
    "    #print(\"最长的序列长度：\",max_len)\n",
    "\n",
    "    padding_id = tokenizer.pad_token_id\n",
    "    #print(\"padding id:\",padding_id)\n",
    "    #print(tokenizer.decode(padding_id))\n",
    "\n",
    "    for io in batch_ids:\n",
    "        l = len(io)\n",
    "        pad = [padding_id for _ in range(max_len - l)]\n",
    "        io += pad\n",
    "\n",
    "    #print(batch_ids)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    padded_batch_tensor = torch.tensor(batch_ids)\n",
    "    #print(padded_batch_tensor)\n",
    "\n",
    "    mask_tensor = get_mask_tensor(io_len)\n",
    "    #print(mask_tensor)\n",
    "\n",
    "    res =  {\n",
    "        \"input_ids\":padded_batch_tensor[:,:-1],\n",
    "        \"labels\":padded_batch_tensor[:,1:],\n",
    "        \"response_mask\":mask_tensor[:,1:]\n",
    "    }\n",
    "\n",
    "    return res\n",
    "\n",
    "tokenize_prompt_and_output(testin,testout,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8fc5a9",
   "metadata": {},
   "source": [
    "### Problem (compute_entropy): Per-token entropy (1 point)\n",
    "\n",
    "**Deliverable:** Implement a method `compute_entropy` that computes the per-token entropy of next-token predictions. The following interface is recommended:\n",
    "\n",
    "```python\n",
    "def compute_entropy(logits: torch.Tensor) -> torch.Tensor:\n",
    "```\n",
    "> Get the entropy of the next-token predictions (i.e., entropy over the vocabulary dimension).\n",
    "\n",
    "- **Args:**\n",
    "    - `logits: torch.Tensor`: Tensor of shape `(batch_size, sequence_length, vocab_size)` containing unnormalized logits.\n",
    "- **Returns:**\n",
    "    - `torch.Tensor`: Shape `(batch_size, sequence_length)`. The entropy for each next-token prediction.\n",
    "\n",
    "**Note:** you should use a numerically stable method (e.g., using `logsumexp`) to avoid overflow.\n",
    "\n",
    "To test your code, implement `adapters.run_compute_entropy`. Then run `uv run pytest -k test_compute_entropy` and ensure your implementation passes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f36a2189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "from jaxtyping import Float, Int, Bool\n",
    "\n",
    "def compute_entropy(\n",
    "    logits: Float[torch.Tensor,\"batch_size sequence_length vocab_size\"]\n",
    ") -> Float[torch.Tensor,\"batch_size sequence_length\"]:\n",
    "    \"\"\"\n",
    "    Get the entropy of the next-token predictions (i.e., entropy over the vocabulary dimension).\n",
    "    Args:\n",
    "        logits(torch.Tensor): Tensor of shape `(batch_size, sequence_length, vocab_size)` containing unnormalized logits.\n",
    "    Returns:\n",
    "        output(torch.Tensor): Shape `(batch_size, sequence_length)`. The entropy for each next-token prediction.\n",
    "    \"\"\"\n",
    "    # 每个位置取对数，乘以自己的相反数，然后沿最后一维求和\n",
    "    print(\"输入：\",logits)\n",
    "\n",
    "    probs = logits.softmax(-1)\n",
    "    \n",
    "\n",
    "\n",
    "    neglogp = - torch.log(probs)\n",
    "    print(\"负对数：\",neglogp)\n",
    "    ent = einops.einsum(logits, neglogp, \"b s v , b s v -> b s v\")\n",
    "    print(\"自身乘以负对数：\",ent)\n",
    "    res = einops.reduce(ent, \"b s v -> b s\", \"sum\")\n",
    "    print(\"结果：\",res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bea8c79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "162b4ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0000, -0.6931, -1.0986])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- torch.log(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6fa10da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['array']\n",
      "array: (2, 10)\n",
      "[[4.1573386 4.25809   4.2000027 4.1944656 4.106727  4.0669866 4.090223\n",
      "  4.0061703 4.149583  4.099516 ]\n",
      " [4.282163  3.8720474 4.1143    4.0242934 4.2255774 4.0835614 4.2772403\n",
      "  4.0522842 4.2011576 4.273294 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(\"/home/nova/cs336/assignment5-alignment/tests/_snapshots/test_compute_entropy.npz\")\n",
    "print(data.files)  \n",
    "\n",
    "for key in data.files:\n",
    "    print(f\"{key}: {data[key].shape}\")\n",
    "    print(data[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e4cbb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入： tensor([[[ 1.9269,  1.4873,  0.9007,  ...,  0.4880,  0.7846,  0.0286],\n",
      "         [ 0.6408,  0.5832,  1.0669,  ...,  0.3581,  0.4788,  1.3537],\n",
      "         [ 0.5261,  2.1120, -0.5208,  ...,  0.2539,  0.9364,  0.7122],\n",
      "         ...,\n",
      "         [-1.2520,  3.0250,  1.3463,  ...,  1.4162,  0.6834, -0.1383],\n",
      "         [ 0.9213,  0.5282, -0.0082,  ..., -0.3867,  0.9578, -0.8225],\n",
      "         [-2.3908,  0.3222,  1.8754,  ..., -0.1493, -0.5523, -0.0934]],\n",
      "\n",
      "        [[-1.0284,  0.4044,  2.1426,  ..., -0.0563, -1.4897, -1.5195],\n",
      "         [ 0.3258, -1.4584,  1.8989,  ...,  1.7561,  0.2113,  1.4860],\n",
      "         [ 0.5585,  0.3491,  0.8484,  ...,  0.0911,  0.6719,  0.9852],\n",
      "         ...,\n",
      "         [-0.6106,  1.0629,  1.2222,  ..., -0.3292, -0.1140, -0.8452],\n",
      "         [ 0.3004,  1.6395, -1.0744,  ...,  0.3046, -0.7002,  1.7811],\n",
      "         [-0.2937,  0.5243,  1.0186,  ..., -1.2133,  0.9745,  0.4532]]])\n",
      "负对数： tensor([[[3.2135, 3.6531, 4.2397,  ..., 4.6524, 4.3558, 5.1118],\n",
      "         [4.4473, 4.5048, 4.0211,  ..., 4.7300, 4.6093, 3.7343],\n",
      "         [4.5839, 2.9979, 5.6307,  ..., 4.8561, 4.1735, 4.3977],\n",
      "         ...,\n",
      "         [6.5566, 2.2796, 3.9584,  ..., 3.8884, 4.6212, 5.4429],\n",
      "         [4.0441, 4.4371, 4.9736,  ..., 5.3521, 4.0076, 5.7879],\n",
      "         [7.4407, 4.7277, 3.1745,  ..., 5.1992, 5.6022, 5.1433]],\n",
      "\n",
      "        [[6.1396, 4.7068, 2.9686,  ..., 5.1675, 6.6009, 6.6307],\n",
      "         [5.0541, 6.8384, 3.4810,  ..., 3.6238, 5.1687, 3.8939],\n",
      "         [4.5339, 4.7433, 4.2441,  ..., 5.0014, 4.4206, 4.1073],\n",
      "         ...,\n",
      "         [5.7069, 4.0334, 3.8742,  ..., 5.4255, 5.2104, 5.9416],\n",
      "         [4.7256, 3.3865, 6.1004,  ..., 4.7214, 5.7262, 3.2449],\n",
      "         [5.3709, 4.5529, 4.0585,  ..., 6.2904, 4.1027, 4.6239]]])\n",
      "自身乘以负对数： tensor([[[  6.1921,   5.4332,   3.8188,  ...,   2.2704,   3.4175,   0.1464],\n",
      "         [  2.8496,   2.6274,   4.2902,  ...,   1.6936,   2.2068,   5.0552],\n",
      "         [  2.4114,   6.3318,  -2.9322,  ...,   1.2330,   3.9083,   3.1322],\n",
      "         ...,\n",
      "         [ -8.2085,   6.8958,   5.3290,  ...,   5.5068,   3.1581,  -0.7525],\n",
      "         [  3.7258,   2.3439,  -0.0409,  ...,  -2.0695,   3.8386,  -4.7607],\n",
      "         [-17.7893,   1.5235,   5.9535,  ...,  -0.7762,  -3.0938,  -0.4805]],\n",
      "\n",
      "        [[ -6.3142,   1.9036,   6.3605,  ...,  -0.2909,  -9.8335, -10.0750],\n",
      "         [  1.6467,  -9.9733,   6.6102,  ...,   6.3639,   1.0921,   5.7865],\n",
      "         [  2.5323,   1.6561,   3.6005,  ...,   0.4555,   2.9700,   4.0464],\n",
      "         ...,\n",
      "         [ -3.4844,   4.2873,   4.7349,  ...,  -1.7861,  -0.5941,  -5.0219],\n",
      "         [  1.4198,   5.5522,  -6.5544,  ...,   1.4380,  -4.0097,   5.7795],\n",
      "         [ -1.5773,   2.3871,   4.1342,  ...,  -7.6319,   3.9979,   2.0957]]])\n",
      "结果： tensor([[ -90.8289,  -50.5721,  -68.7912,  -85.5457,  -90.7824, -151.5848,\n",
      "          -79.0051,  -73.5918, -182.0801, -132.6149],\n",
      "        [ -13.7322,  -47.4912,  -98.1791, -140.6179,  -82.2795, -179.6641,\n",
      "          -73.4825, -135.3148, -121.5303,  -40.8543]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ -90.8289,  -50.5721,  -68.7912,  -85.5457,  -90.7824, -151.5848,\n",
       "          -79.0051,  -73.5918, -182.0801, -132.6149],\n",
       "        [ -13.7322,  -47.4912,  -98.1791, -140.6179,  -82.2795, -179.6641,\n",
       "          -73.4825, -135.3148, -121.5303,  -40.8543]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "inputs = torch.randn(size=(2,10,100))\n",
    "compute_entropy(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5259844e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0556,  1.4968,  0.3602],\n",
      "         [-1.2984,  0.3366, -0.5514]]])\n",
      "输入： tensor([[[ 1.0556,  1.4968,  0.3602],\n",
      "         [-1.2984,  0.3366, -0.5514]]])\n",
      "负对数： tensor([[[1.1163, 0.6751, 1.8117],\n",
      "         [2.1090, 0.4740, 1.3620]]])\n",
      "自身乘以负对数： tensor([[[ 1.1784,  1.0104,  0.6526],\n",
      "         [-2.7382,  0.1596, -0.7510]]])\n",
      "结果： tensor([[ 2.8414, -3.3296]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8414, -3.3296]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.randn(size=(1,2,3))\n",
    "print(test)\n",
    "compute_entropy(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
